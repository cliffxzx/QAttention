{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/miniconda3/envs/py39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-06-21 11:32:10.229294: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ~/tensorflow_datasets/fashion_mnist_dataset/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.46 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.46 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.46 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:02,  1.46 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.78 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.78 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.78 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:02<00:01,  1.78 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:03<00:01,  1.78 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:03<00:01,  1.78 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:04<00:01,  1.78 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:04<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:04<00:01,  1.82s/ url]\n",
      "\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:04<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:06<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:08<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:09<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:09<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:10<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:10<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:11<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:11<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:11<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:12<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:12<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:12<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:12<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:13<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:13<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:13<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:13<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:14<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:14<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:14<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:14<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:14<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:14<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:15<00:01,  1.82s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:15<00:01,  1.82s/ url]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:15<00:00,  5.34s/ url]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:15<00:00,  5.34s/ url]\n",
      "\u001b[A\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:15<00:00,  5.34s/ url]\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:15<00:00,  3.93s/ file]\n",
      "Dl Size...: 100%|██████████| 29/29 [00:15<00:00,  1.84 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:15<00:00,  3.93s/ url]\n",
      "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]2022-06-21 11:32:27.277923: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-21 11:32:27.278915: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-21 11:32:27.279490: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset fashion_mnist_dataset downloaded and prepared to ~/tensorflow_datasets/fashion_mnist_dataset/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets.public_api as tfds\n",
    "\n",
    "import sys\n",
    "sys.path += ['../']\n",
    "\n",
    "from datasets.MNISTDataset import MNISTDataset, FashionMNISTDataset\n",
    "\n",
    "raw_ds = tfds.load('FashionMNISTDataset', split='train', as_supervised=True)\n",
    "\n",
    "# insert after `.shuffle` function line at 15 if you want data process\n",
    "# .map(lambda x, y: (tf.reshape(tf.image.resize(x, (4,4)), [16]), tf.one_hot(tf.cast(y, tf.int32), 10)))\\\n",
    "ds = raw_ds\\\n",
    "    .shuffle(buffer_size=1000)\\\n",
    "    .map(lambda x, y: (x, tf.one_hot(tf.cast(y, tf.int32), 10)))\\\n",
    "    .batch(256)\\\n",
    "\n",
    "train_ds, test_ds = ds.take(int(len(ds) * 0.83)), ds.skip(int(len(ds) * 0.83))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - 12s 1s/step - loss: 7.9430 - categorical_accuracy: 0.1008\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 11:33:06.878924: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 10s 1s/step - loss: 7.7699 - categorical_accuracy: 0.0965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 11:33:17.342861: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 336ms/step - loss: 8.5785 - categorical_accuracy: 0.1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 11:33:21.802665: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.578466415405273, 0.10234375298023224]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow.keras.layers as nn\n",
    "\n",
    "from tensorflow import einsum\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.tensorflow import Rearrange\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "class PreNorm(Layer):\n",
    "    def __init__(self, fn):\n",
    "        super(PreNorm, self).__init__()\n",
    "\n",
    "        self.norm = nn.LayerNormalization()\n",
    "        self.fn = fn\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        return self.fn(self.norm(x), training=training)\n",
    "\n",
    "class MLP(Layer):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.0):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        def GELU():\n",
    "            def gelu(x, approximate=False):\n",
    "                if approximate:\n",
    "                    coeff = tf.cast(0.044715, x.dtype)\n",
    "                    return 0.5 * x * (1.0 + tf.tanh(0.7978845608028654 * (x + coeff * tf.pow(x, 3))))\n",
    "                else:\n",
    "                    return 0.5 * x * (1.0 + tf.math.erf(x / tf.cast(1.4142135623730951, x.dtype)))\n",
    "\n",
    "            return nn.Activation(gelu)\n",
    "\n",
    "        self.net = Sequential([\n",
    "            nn.Dense(units=hidden_dim),\n",
    "            GELU(),\n",
    "            nn.Dropout(rate=dropout),\n",
    "            nn.Dense(units=dim),\n",
    "            nn.Dropout(rate=dropout)\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        return self.net(x, training=training)\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.0):\n",
    "        super(Attention, self).__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax()\n",
    "        self.to_qkv = nn.Dense(units=inner_dim * 3, use_bias=False)\n",
    "\n",
    "        if project_out:\n",
    "            self.to_out = [\n",
    "                nn.Dense(units=dim),\n",
    "                nn.Dropout(rate=dropout)\n",
    "            ]\n",
    "        else:\n",
    "            self.to_out = []\n",
    "\n",
    "        self.to_out = Sequential(self.to_out)\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        qkv = self.to_qkv(x)\n",
    "        qkv = tf.split(qkv, num_or_size_splits=3, axis=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n",
    "\n",
    "        # dots = tf.matmul(q, tf.transpose(k, perm=[0, 1, 3, 2])) * self.scale\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        # x = tf.matmul(attn, v)\n",
    "        x = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        x = rearrange(x, 'b h n d -> b n (h d)')\n",
    "        x = self.to_out(x, training=training)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Transformer(Layer):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.0):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.layers = []\n",
    "\n",
    "        for _ in range(depth):\n",
    "            self.layers.append([\n",
    "                PreNorm(Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n",
    "                PreNorm(MLP(dim, mlp_dim, dropout=dropout))\n",
    "            ])\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        for attn, mlp in self.layers:\n",
    "            x = attn(x, training=training) + x\n",
    "            x = mlp(x, training=training) + x\n",
    "\n",
    "        return x\n",
    "\n",
    "class ViT(Model):\n",
    "    def __init__(self, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim,\n",
    "                 pool='cls', dim_head=64, dropout=0.0, emb_dropout=0.0):\n",
    "        \"\"\"\n",
    "            image_size: int.\n",
    "            -> Image size. If you have rectangular images, make sure your image size is the maximum of the width and height\n",
    "            patch_size: int.\n",
    "            -> Number of patches. image_size must be divisible by patch_size.\n",
    "            -> The number of patches is: n = (image_size // patch_size) ** 2 and n must be greater than 16.\n",
    "            num_classes: int.\n",
    "            -> Number of classes to classify.\n",
    "            dim: int.\n",
    "            -> Last dimension of output tensor after linear transformation nn.Linear(..., dim).\n",
    "            depth: int.\n",
    "            -> Number of Transformer blocks.\n",
    "            heads: int.\n",
    "            -> Number of heads in Multi-head Attention layer.\n",
    "            mlp_dim: int.\n",
    "            -> Dimension of the MLP (FeedForward) layer.\n",
    "            dropout: float between [0, 1], default 0..\n",
    "            -> Dropout rate.\n",
    "            emb_dropout: float between [0, 1], default 0.\n",
    "            -> Embedding dropout rate.\n",
    "            pool: string, either cls token pooling or mean pooling\n",
    "        \"\"\"\n",
    "        super(ViT, self).__init__()\n",
    "\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.patch_embedding = Sequential([\n",
    "            Rearrange('b (h p1) (w p2) c -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width),\n",
    "            nn.Dense(units=dim)\n",
    "        ], name='patch_embedding')\n",
    "\n",
    "        self.pos_embedding = tf.Variable(initial_value=tf.random.normal([1, num_patches + 1, dim]))\n",
    "        self.cls_token = tf.Variable(initial_value=tf.random.normal([1, 1, dim]))\n",
    "        self.dropout = nn.Dropout(rate=emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "\n",
    "        self.mlp_head = Sequential([\n",
    "            nn.LayerNormalization(),\n",
    "            nn.Dense(units=num_classes)\n",
    "        ], name='mlp_head')\n",
    "\n",
    "    def call(self, img, training=True, **kwargs):\n",
    "        x = self.patch_embedding(img)\n",
    "        b, n, d = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b=b)\n",
    "        x = tf.concat([cls_tokens, x], axis=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        x = self.transformer(x, training=training)\n",
    "\n",
    "        if self.pool == 'mean':\n",
    "            x = tf.reduce_mean(x, axis=1)\n",
    "        else:\n",
    "            x = x[:, 0]\n",
    "\n",
    "        x = self.mlp_head(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model = ViT(\n",
    "    image_size = 28,\n",
    "    patch_size = 4,\n",
    "    num_classes = 10,\n",
    "    dim = 10,\n",
    "    depth = 5,\n",
    "    heads = 4,\n",
    "    mlp_dim = 20,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics=tf.keras.metrics.CategoricalAccuracy()\n",
    ")\n",
    "\n",
    "model.run_eagerly = True\n",
    "model.fit(train_ds.take(10), epochs=2)\n",
    "model.evaluate(test_ds.take(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d491c5efa58df3efa9c09029eade2e2c7ef755a4c09009d5c493a74229ae693"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
